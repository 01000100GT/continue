import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

# Groq

Groq provides the fastest available inference for open-source language models, including the entire Llama 3.1 family.

1. Obtain an API key [here](https://console.groq.com/keys)
2. Update your Continue config file like this:

<Tabs groupId="config-example">
  <TabItem value="yaml" label="YAML">
    ```yaml title="Package or config.yaml"
    models:
      - name: Llama 3.1 405b
        provider: groq
        model: llama3.1-405b
        apiKey: ${{ secrets.GROQ_API_KEY }}
        roles:
          - chat
    ```
  </TabItem>
  <TabItem value="json" label="JSON">
    ```json title="config.json (Deprecated)"
    "models": [
      {
        "title": "Llama 3.1 405b",
        "provider": "groq",
        "model": "llama3.1-405b",
        "apiKey": "<API_KEY>"
      }
    ]
    ```
  </TabItem>
</Tabs>
